{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "641e0097-2839-45bc-acb1-b73ab815e58c",
   "metadata": {},
   "source": [
    "# Unit 6. Essential Deep Learning Tips & Tricks\n",
    "\n",
    "## 6.8 Debugging Deep Neural Networks\n",
    "\n",
    "## Part 3. Fast Dev Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eec68953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "torch       : 2.1.2+cu121\n",
      "lightning   : 2.1.4\n",
      "torchmetrics: 1.2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -p torch,lightning,torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e80fef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "from shared_utilities import CustomDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b119b7c9-18ac-4c89-a574-a1c63783605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchMLP(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.all_layers = torch.nn.Sequential(\n",
    "            # 1st hidden layer\n",
    "            torch.nn.Linear(num_features, 100),\n",
    "            torch.nn.BatchNorm1d(100),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 2nd hidden layer\n",
    "            torch.nn.Linear(100, 50),\n",
    "            torch.nn.BatchNorm1d(50),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # output layer\n",
    "            torch.nn.Linear(50, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        logits = self.all_layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26845f11-4a0d-48f3-818a-22e4093b79ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningModel(L.LightningModule):\n",
    "    def __init__(self, model, learning_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _shared_step(self, batch):\n",
    "        features, true_labels = batch\n",
    "        logits = self(features)\n",
    "\n",
    "        loss = F.cross_entropy(logits, true_labels)\n",
    "        predicted_labels = torch.argmax(logits, dim=1)\n",
    "        return loss, true_labels, predicted_labels\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.train_acc(predicted_labels, true_labels)\n",
    "        self.log(\n",
    "            \"train_acc\", self.train_acc, prog_bar=True, on_epoch=True, on_step=False\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.val_acc(predicted_labels, true_labels)\n",
    "        self.log(\"val_acc\", self.val_acc, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "        self.test_acc(predicted_labels, true_labels)\n",
    "        self.log(\"test_acc\", self.test_acc)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa7bcf14-8046-4213-accf-544b67e74883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 5 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "L.seed_everything(123)\n",
    "dm = CustomDataModule()\n",
    "\n",
    "pytorch_model = PyTorchMLP(num_features=100, num_classes=2)\n",
    "lightning_model = LightningModel(model=pytorch_model, learning_rate=0.15)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    fast_dev_run=5,\n",
    "    max_epochs=100,\n",
    "    accelerator=\"cpu\",\n",
    "    devices=\"auto\",\n",
    "    #logger=CSVLogger(save_dir=\"logs/\", name=\"my-model\"),\n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14d23b49-4c47-4bb1-bf6c-b87aabf0b22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | PyTorchMLP         | 15.6 K\n",
      "1 | train_acc | MulticlassAccuracy | 0     \n",
      "2 | val_acc   | MulticlassAccuracy | 0     \n",
      "3 | test_acc  | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------\n",
      "15.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.6 K    Total params\n",
      "0.062     Total estimated model params size (MB)\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cddc40cbb2f4df88df2fb6698a49eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8870afcc2a5441e8a1d70b0e2cc5e8f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=lightning_model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6732385",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
    "\n",
    "aggreg_metrics = []\n",
    "agg_col = \"epoch\"\n",
    "for i, dfg in metrics.groupby(agg_col):\n",
    "    agg = dict(dfg.mean())\n",
    "    agg[agg_col] = i\n",
    "    aggreg_metrics.append(agg)\n",
    "\n",
    "df_metrics = pd.DataFrame(aggreg_metrics)\n",
    "df_metrics[[\"train_loss\", \"val_loss\"]].plot(\n",
    "    grid=True, legend=True, xlabel=\"Epoch\", ylabel=\"Loss\"\n",
    ")\n",
    "\n",
    "plt.ylim([0.0, 0.9])\n",
    "plt.savefig(\"step_loss.pdf\")\n",
    "\n",
    "df_metrics[[\"train_acc\", \"val_acc\"]].plot(\n",
    "    grid=True, legend=True, xlabel=\"Epoch\", ylabel=\"ACC\"\n",
    ")\n",
    "\n",
    "plt.ylim([0.7, 1.0])\n",
    "plt.savefig(\"step_acc.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a7e4b8-a243-4a2b-99a9-35b32dbf0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model=lightning_model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e04d95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
